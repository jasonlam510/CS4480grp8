---
description: Enforce HDFS + HBase storage model and Big Data constraints for CS4480grp8.
globs:
  - "docker/**"
  - "compose/**"
  - "infra/**"
  - "hadoop/**"
  - "spark/**"
  - "scripts/**"
  - "src/**/*.py"
  - "src/**/*.sh"
alwaysApply: false
---

Storage constraints for CS4480grp8:

HDFS:
- Treat **HDFS as the canonical store** for all raw and processed video data.
- Raw video files **must be stored in HDFS** under a path like:
  - `/hdfs_raw_data/`
- Preprocessed / feature data **must be stored in HDFS** under a path like:
  - `/hdfs_processed_data/`
- Do not design the main pipeline to depend on local paths (e.g., `./data`, `/tmp`) for primary data storage. Local paths may be used only for small, temporary debugging files.
- Respect the **write-once-read-many** model:
  - Do not update HDFS files in place.
  - Prefer writing new versioned paths (e.g., `/hdfs_processed_data/v2/...`).
- Assume **block replication** is enabled for fault tolerance. Do not remove or “optimize away” replication in config examples.

HBase:
- All **semi-structured metadata** (video IDs, timestamps, location tags, titles, tags, etc.) must live in **HBase**, which is a **column-oriented store on top of HDFS**.
- When you need random lookups (e.g., by video_id, time window, location tag), prefer **HBase queries** rather than scanning flat files.
- When adding metadata, extend HBase schemas instead of creating ad-hoc JSON/CSV files as the main source of truth.
- Promote a clear schema pattern, for example:
  - Row key: `video_id` or `video_id#timestamp`
  - Column families: `meta`, `tags`, `geo`, etc.

General:
- When generating code, default to HDFS or HBase access patterns instead of local filesystem IO.
- If you propose changes that would move core data off HDFS/HBase, explicitly mark that as **not allowed** for this project.
